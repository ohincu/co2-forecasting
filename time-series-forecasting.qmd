---
title: CO2 Concentration Forecasting 
format: html
editor: visual
---

# Loading libraries

```{r}
library(tidyverse)
library(lubridate)
library(zoo)
library(forecast)
# Hide warnings
options(warn = -1, repr.plot.width = 10, repr.plot.height = 6, repr.plot.res = 150 )
```

Adding a standard theme

```{r}
# Adding Lato font
library(showtext)
font_add_google("lato", "lato.ttf")
showtext_auto()

my_theme <- function(text_color) {
  theme_bw() +
    theme(text = element_text(size = 12, family = "lato", face = "bold", color = text_color),
          panel.grid.minor = element_blank(),
          panel.grid.major = element_blank(),
          plot.title = element_text(hjust = 0.5)
    )
}
```

# Getting data

The data comes from Mauna Loa in Hawaii, and it contains monthly average measurements of CO2. It is not identical to the entire atmospheric average, but it's pretty close.

```{r}
data <- read.delim('ftp://aftp.cmdl.noaa.gov/products/trends/co2/co2_mm_mlo.txt', comment.char = '#', header = F, sep = '', col.names = c('year','month','decimal_date','co2_average','co2_deseasonalized','days','st_dev_days', 'unc'))
```

# EDA

Let's have a first look at the data.

```{r}
head(data)
summary(data)
```

We've got data from 1958 until December 2023.

```{r}
which(is.na(data))
```

And no Nas.

## Manipulations

Let's do 3 things:

1.  Add a date to be able to create a ts.
2.  Select only relevant data.
3.  Split the data into train and test.

```{r}
data$date <- ymd(paste0(data$year, " ", data$month, " ", "15"))
data_sel <- data %>% select(year, month, date, co2_average)

data_test <- data_sel %>% filter(year > 2020)
data_train <- data_sel %>% filter(year <= 2020)
```

Ready. Let's see now how the CO2 concentration changed in time.

```{r}
ggplot(data_sel, aes(date, co2_average)) +
  geom_line(color = 'darkorange') +
  scale_x_date(date_labels = "%Y-%m", date_breaks = "10 year") +
  xlab("Year-Month") +
  ylab("CO2 Concentration (ppm)") +
  ggtitle("CO2 Concentration Progress In Time") +
  my_theme(text_color = "black")
```

-   The CO2 concentration in ppm follows an approximately exponential trend lately. Ppm stands for "parts per million of carbon dioxide" and represents the number of CO2 molecules present in the atmosphere for every one million molecules

-   [ðŸ›ˆ](https://emojipedia.org/circled-information-source) The baseline pre-industrial atmospheric CO2 concentration is considered to be around 280 ppm and it was like this for [10000 years](https://www.climate.gov/media/14605)Â up to the industrial revolution. Currently it's way over 400.

Let's check the growth rates.

```{r}
# Calculate the monthly changes (comparing January with January last year, and so on)
data_sel <- data_sel %>%
  mutate(monthly_change = co2_average - lag(co2_average, n = 12))

# Calculate annual growth rate
annual_growth_rate <- data_sel %>%
  group_by(year) %>%
  summarize(avg_ppm = mean(monthly_change, na.rm = TRUE)) 

annual_growth_rate %>% 
  ggplot(aes(year, avg_ppm)) +
  geom_line(color = 'darkorange') + 
  geom_hline(yintercept = 2, color = 'grey') +
  xlab("Year") +
  ylab("Average Yearly CO2 Change (ppm) in %") +
  my_theme(text_color = "black")
```

It's increasing, with about 2.5ppm increase in 2023. This not very reliable though, as it includes the seasonal effects. I would still check original sources, such as <https://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide>.

I want to also look closer, and see how the CO2 concentration changes through the year.

```{r}
# Creating a tsibble object for plotting and modeling
co2_train <- ts(data_train$co2_average, start = c(1958,3), frequency = 12) # 12 as we have monthly data
co2_test <- ts(data_test$co2_average, start = c(2021,1), frequency = 12)

co2_train %>% 
  ggseasonplot() +
  ggtitle("Seasonal Plot By Year") +
  xlab("Month") +
  ylab("CO2 Concentration (ppm)") +
  my_theme(text_color = "black") +
  theme(legend.position = "none")
```

-   The monthly seasonal variation is almost the same across years.

-   The CO2 concentration increases up to May, then drops and increases again in October. According to [NOAA](https://www.climate.gov/news-features/understanding-climate/climate-change-atmospheric-carbon-dioxide), this is driven by Northern Hemisphere summer vegetation growth, which reduces atmospheric CO2, and winter decay, which increases it.

## Time Series Analysis

Before applying the ARIMA model, I need to check 2 things: stationarity and correlations between time lags.

```{r}
co2_train %>% ggtsdisplay(lag.max = 90)
```

-   The data is clearly not stationary having an increasing trend and seasonality.

-   The significant lag at 12 potentially suggests annual seasonality and 25 might hide some longer-term seasonality.

```{r}
co2_train %>% diff() %>% diff(lag = 12) %>% ggtsdisplay(lag.max = 90)
```

That looks stationary.

**More details:**

-   Slow decay in the ACF and significant lag at 1 in the PACF might suggest an AR(1) component.

-   A significant lag at 1 in the PACF suggests a MA(1).

-   And the significants lags in PACF might indicate a MA(2) or MA(3) in the seasonal part.

-   And of course the 12 lag, 24, 36 and so on, might indicate the seasonal part.

I'll use auto.arima first, as it's usually good at detecting these patterns.

```{r}
fit = auto.arima(co2_train)
print(fit)
```

-   OK, so the auto.arima model actually taps into what I had just mentioned.

-   The MA(2) in the seasonal part, might be due to a couple of significant lags in the PACF and the AR(2) due to the decay in ACF and again, the significant lags in PACF.

    Let's check if there is any trend left in the residuals by using a Ljung Box test.

[ðŸ›ˆ](https://emojipedia.org/circled-information-source) TheÂ Ljung-Box statistic is used for testing if a time series is white noise.

```{r}
residuals <- residuals(fit)
ljung_box_test <- Box.test(residuals, lag = 60, type = "Ljung-Box")
print(ljung_box_test)
```

With a p-value \> 0.05, there is not enough evidence to reject the null hypothesis. Based on the Box-Ljung test, there is no significant autocorrelation in the residuals at the specified lags, thus, we can say the time series is stationary.

# Forecasting with ARIMA

I chose a seasonal ARIMA model because it works well with time series data, which relies on past values. Since CO2 concentration is linked to its previous levels, this model seemed like a good fit. I understand that using a simple model like ARIMA on CO2 concentration might oversimplify the results. However, my main goal is to see if the model can accurately detect seasonal patterns.

ARIMA is generally used to forecast a couple of months ahead, not more. After this, there is too much uncertainty that cannot be covered by the model.

Nevertheless, I will forecast the next 30 years to check this assumption.

```{r}
arima_forecast <- co2_train %>%
  Arima(order = c(1,1,1), seasonal = list(order = c(2,1,2),period = 12),
        lambda = "auto"
  ) %>%
  forecast(h = 12 * 30) # next 30 years

arima_forecast %>%
  autoplot() +
  xlab("Year") +
  ylab("Co2 Concentration in PPM") +
  autolayer(co2_test)
```

-   ARIMA seems to drop its CO2 concentration growth rates in time. But I doubt that would be our case.

-   ARIMA does not notice the strong increasing trend in CO2 concentration. Fair enough, it's also "a bit" far in time, so we cannot expect much from such a simple model.

```{r}
df_arima_forecast <- data.frame(arima_forecast)

df_arima_forecast %>% 
  mutate(monthly_change = Point.Forecast - lag(Point.Forecast, n = 12)) %>% 
  summarise(rolling_avg = rollmean(monthly_change, na.rm = TRUE, k = 12)) %>% 
  ggplot(aes(rolling_avg)) +
  geom_histogram() +
  xlab("Average Monthly Change in ppm") +
  ylab("# Months")
```

\
Here, it's the rolling average for each year as a distribution and it's mostly constant.
